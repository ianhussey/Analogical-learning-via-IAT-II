amp_recognition_scale <-
trimmed_df %>%
dplyr::filter(!is.na(amp_recognition_response)) %>%
dplyr::select(participant, amp_recognition_response)
participants_with_full_data <-
dplyr::semi_join(participants_with_full_data, amp_recognition_scale, by = "participant")
# participants with at least partial data
participants_with_at_least_partial_data <-
trimmed_df %>%
dplyr::distinct(participant) %>%
dplyr::mutate(participant_partial = participant)
# participants with incomplete data
participants_with_incomplete_data <-
dplyr::anti_join(participants_with_at_least_partial_data, participants_with_full_data, by = "participant")
# make lists of participants ----------------------------------------------
## produce prolific codes so that participants can be credited or rejected
# 1. prolific codes for participants with complete data so that they can be paid
prolific_codes_for_complete_participants <-
dplyr::inner_join(trimmed_df, participants_with_full_data, by = "participant") %>%
dplyr::filter(trialcode == "ProlificCode") %>%
dplyr::select(participant, response) %>%
dplyr::distinct(participant, .keep_all = TRUE)
# participants to credit
prolific_codes_for_complete_participants %>% readr::write_csv("data/processed data/prolific codes - complete data.csv")
# participant with complete data - i.e., the inclusion list
prolific_codes_for_complete_participants %>% select(participant) %>% readr::write_csv("data/processed data/inclusion list.csv")
# 1.1 N of complete participants
prolific_codes_for_complete_participants %>% dplyr::summarize(participant = n())
# 2. prolific codes for participants with incomplete data so that they can be rejected
prolific_codes_for_incomplete_participants <-
dplyr::inner_join(trimmed_df, participants_with_incomplete_data, by = "participant") %>%
dplyr::filter(trialcode == "ProlificCode") %>%
dplyr::select(participant, response) %>%
dplyr::distinct(participant, .keep_all = TRUE)
prolific_codes_for_incomplete_participants %>% readr::write_csv("data/processed data/prolific codes - incomplete data.csv")
# 2.1 N of incomplete participants
prolific_codes_for_incomplete_participants %>% dplyr::summarize(participant = n())
# 2.2 rejected participants will automatically have their slots reopened and fresh data will be collected.
# 3 Misfits on the prolific site
# the list of participants on prolific will still probably include a number of remaining participants. for example:
# 1. Those who cancelled all tasks (and therefore recorded no inquisit data but nonetheless returned a
# completion code to prolific). These should be REJECTED. If they are not, they'll be paid automatically after two weeks.
# 2. Those who entered an incorrect prolific id or did not enter one, but who nonetheless produced legitimate data.
# These should be APPROVED.
# process data
# author: Ian Hussey (ian.hussey@ugent.be)
# license: GPLv3+
# Notes:
# ProlificCode is used only to pay participants and must be deleted from
# all data files before raw data is posted online
# Dependencies ------------------------------------------------------------
library(plyr)
library(tidyverse)
library(data.table)
library(schoRsch)
# Data acquisition and cleaning -------------------------------------------
## Set the working directory
setwd("/Users/Ian/Dropbox/Work/Projects/Analogy/1 analogical learning via IAT with known stimuli/Experiment 2/data/raw data/")
# Read all files with the .iqdat extension
files <- list.files(pattern = "\\.csv$")
# Read these files sequentially into a single data frame
input_df <- dplyr::tbl_df(plyr::rbind.fill(lapply(files, data.table::fread, header = TRUE)))  # tbl_df() requires dplyr, rbind.fill() requires plyr, fread requires data.table
setwd("/Users/Ian/Dropbox/Work/Projects/Analogy/1 analogical learning via IAT with known stimuli/Experiment 2/")
# Make some variable names more transparent
cleaned_df <-
input_df %>%
dplyr::select(subject,
date,
time,
blockcode,  # name of block
blocknum,
trialnum,
response,  # for string responses
correct,
latency,
trialcode,
amp_recognition_response) %>%
dplyr::rename(participant = subject,
block_name = blockcode,
block_n = blocknum,
trial_n = trialnum,
accuracy = correct,
rt = latency) %>%
dplyr::mutate(participant = as.numeric(participant),
block_n = as.numeric(block_n),
trial_n = as.numeric(trial_n),
accuracy = as.numeric(accuracy),
rt = as.numeric(rt))
# MANUAL INCLUSIONS HERE - ONLY THOSE WITH COMPLETE DATA
inclusion_df <- read.csv("data/processed data/inclusion list.csv")
cleaned_df <- dplyr::inner_join(cleaned_df, inclusion_df, by = "participant")
###########################################################################
# wide data
###########################################################################
# demographics and parameters  --------------------------------------------
demo_temp_1_df <-
cleaned_df %>%
dplyr::group_by(participant) %>%
dplyr::filter(grepl("demographics", block_name),
trialcode == "age") %>%  # filter rows where the block_name includes string
dplyr::rename(age = response) %>%
dplyr::mutate(age = as.numeric(age)) %>%
dplyr::select(participant, age) %>% # select only necessary columns
dplyr::distinct(participant, .keep_all = TRUE)
demo_temp_2_df <-
cleaned_df %>%
dplyr::group_by(participant) %>%
dplyr::filter(grepl("demographics", block_name),
trialcode == "gender") %>%  # filter rows where the block_name includes string
dplyr::rename(gender = response) %>%
dplyr::select(participant, gender) %>% # select only necessary columns
dplyr::distinct(participant, .keep_all = TRUE) %>%
dplyr::mutate(gender = tolower(gender),  # homogenise gender categories. first make lower case
gender = ifelse(gender == "f", "female",  # then convert abbreviations
ifelse(gender == "m", "male", gender))) %>%
dplyr::left_join(demo_temp_1_df, by = "participant")
demo_temp_3_df <-
cleaned_df %>%
dplyr::filter(grepl("demographics", block_name)) %>%
dplyr::distinct(participant) %>%
dplyr::group_by(participant) %>%
dplyr::mutate(condition = participant %% 8,
condition = ifelse(condition == 0, 8, condition),  # convert participant codes to conditions and correct modulus%%8==0 to condition=8
IAT_condition = ifelse(condition <= 4, "Race IAT", "Flowers-Insects IAT"),
block_order = ifelse(condition %% 2 == 1, "congruent", "incongruent"),
task_order = ifelse(condition == 1 | condition == 2 | condition == 5 | condition == 6,
"ratings first", "SCIAT first")) %>%
dplyr::left_join(demo_temp_2_df, by = "participant")
# amp recognition
demographics_df <-
cleaned_df %>%
dplyr::filter(!is.na(amp_recognition_response)) %>%
dplyr::select(participant, amp_recognition_response) %>%
dplyr::left_join(demo_temp_3_df, by = "participant")
# ratings -----------------------------------------------------------------
ratings_df <-
cleaned_df %>%
dplyr::filter(grepl("ratings", block_name)) %>%  # filter rows where the trialcode includes string
dplyr::rename(ratings = response) %>%
dplyr::select(participant, ratings) %>%
dplyr::group_by(participant) %>%
dplyr::mutate(ratings = as.integer(ratings)) %>%
dplyr::summarize(mean_rating = round(mean(ratings), 2))
# modern racism scale -----------------------------------------------------
racism_scale_df <-
cleaned_df %>%
dplyr::filter(grepl("racism_scale", block_name)) %>%  # filter rows where the trialcode includes string
dplyr::select(participant, response) %>%
dplyr::group_by(participant) %>%
dplyr::mutate(response = as.integer(response)) %>%
dplyr::summarize(modern_racism_scale_total = sum(response))
# IAT summary scores ------------------------------------------------------
IAT_summary_stats_df <-
cleaned_df %>%
dplyr::filter(block_name == "compatibletest1" |
block_name == "compatibletest2" |
block_name == "incompatibletest1" |
block_name == "incompatibletest2") %>% # test blocks only
dplyr::mutate(IAT_too_fast_trial = ifelse(rt < 300, 1, 0)) %>%
dplyr::group_by(participant) %>%
dplyr::summarize(IAT_mean_RT = round(mean(rt), 0),
IAT_perc_acc = round(sum(accuracy)/n(), 2),
IAT_percent_fast_trials = sum(IAT_too_fast_trial)/n()) %>%  # arbitrary number of test block trials
dplyr::mutate(IAT_exclude_based_on_fast_trials = ifelse(IAT_percent_fast_trials < 0.1, FALSE, TRUE)) %>%
dplyr::select(participant,
IAT_mean_RT,
IAT_perc_acc,
IAT_exclude_based_on_fast_trials)
# AMP summary scores ------------------------------------------------------
# AMP_summary_stats_df <-
#   cleaned_df %>%
#   dplyr::filter(block_name == "AMP_test") %>% # test block only
#   dplyr::select(participant,
#                 accuracy,
#                 rt,
#                 trialcode) %>%
#   dplyr::mutate(AMP_too_fast_trial = ifelse(rt < 300, 1, 0)) %>%
#   dplyr::group_by(participant) %>%
#   dplyr::summarize(AMP_mean_RT = round(mean(rt), 0),
#                    AMP_perc_acc = round(sum(accuracy)/n(), 2),
#                    AMP_percent_fast_trials = sum(AMP_too_fast_trial)/n()) %>%  # arbitrary number of test block trials
#   dplyr::mutate(AMP_exclude_based_on_fast_trials = ifelse(AMP_percent_fast_trials < 0.1, FALSE, TRUE)) %>%
#   dplyr::select(participant,
#                 AMP_mean_RT,
#                 AMP_perc_acc,
#                 AMP_exclude_based_on_fast_trials)
## The exclusion criterion of >10% trials <300ms was illconsidered - it didn't take into account the distribution
## of RTs in the AMP and results in a very large proportion of the sample being excluded.
## Rather than tweak this exclusion criterion post hoc, we simple remove it for the sake of improving attrition rates.
## This change was made prior to analysing the data.
AMP_summary_stats_df <-
cleaned_df %>%
dplyr::filter(block_name == "AMP_test") %>% # test block only
dplyr::select(participant,
accuracy,
rt,
trialcode) %>%
dplyr::group_by(participant) %>%
dplyr::summarize(AMP_mean_RT = round(mean(rt), 0),
AMP_perc_acc = round(sum(accuracy)/n(), 2)) %>%  # arbitrary number of test block trials
dplyr::select(participant,
AMP_mean_RT,
AMP_perc_acc)
# join wide D1 scored data and write to disk ------------------------------
wide_data_df <-
plyr::join_all(list(as.data.frame(demographics_df),  # join_all throws a requires input be data.frame error, despite is.data.frame returning TRUE for all members of list. Workaround is to coerce all to DF here.
as.data.frame(racism_scale_df),
as.data.frame(IAT_summary_stats_df),
as.data.frame(AMP_summary_stats_df)),
by = "participant",
type = "full") %>%
dplyr::arrange(participant) %>%
dplyr::mutate(exclude = ifelse(IAT_exclude_based_on_fast_trials == TRUE, TRUE,
#ifelse(AMP_exclude_based_on_fast_trials == TRUE, TRUE,
FALSE))
# print N
wide_data_df %>% dplyr::summarize(condition_count = n())
wide_data_df %>% write.csv(file = "data/processed data/wide data.csv", row.names = FALSE)
###########################################################################
# long format data
###########################################################################
# other tasks -------------------------------------------------------------
other_tasks_df <-
wide_data_df %>%
dplyr::select(participant,
IAT_condition,
block_order,
task_order,
gender,
age,
modern_racism_scale_total,
amp_recognition_response,
IAT_exclude_based_on_fast_trials,
#AMP_exclude_based_on_fast_trials,
exclude)
# long format AMP ratings -------------------------------------------------
AMP_long_format_df <-
cleaned_df %>%
dplyr::filter(block_name == "AMP_test") %>%
dplyr::select(participant,
accuracy,
rt,
trialcode) %>%
dplyr::left_join(other_tasks_df, by = "participant")
AMP_long_format_df %>% write.csv(file = "data/processed data/long AMP data.csv", row.names = FALSE)
# long format ratings -----------------------------------------------------
ratings_long_format_df <-
cleaned_df %>%
dplyr::filter(block_name == "ratings") %>%
dplyr::mutate(rating = as.integer(response)) %>%
dplyr::select(participant,
trial_n,
rating) %>%
dplyr::left_join(other_tasks_df, by = "participant")
ratings_long_format_df %>% write.csv(file = "data/processed data/long ratings data.csv", row.names = FALSE)
# dependencies
library(tidyverse)
library(psych)
library(afex)
library(effsize)
library(weights)  # for rd(), a round() alternative
library(plotrix)  # for std.error
setwd(params$location_of_data)
data_df <-
read.csv("processed data/wide data.csv") %>%
mutate(gender = as.factor(gender))
colnames(data_df)
data_df %>% dplyr::count(gender)
data_df %>%
dplyr::select(age) %>%
psych::describe(fast = TRUE,  # subset of descriptive stats
ranges = FALSE,
trim = 0) %>%
dplyr::select(-vars, -se)
passers_df <-
data_df %>%
dplyr::filter(exclude == FALSE)
passers_df %>% dplyr::count(IAT_condition)
passers_df %>%
dplyr::select(IAT_mean_RT,
IAT_perc_acc,
AMP_mean_RT,
AMP_perc_acc) %>%
psych::describe(fast = TRUE,  # subset of descriptive stats
ranges = FALSE,
trim = 0) %>%
dplyr::select(-vars, -se)
View(passers_df)
View(passers_df)
# get data
setwd(params$location_of_data)
AMP_data <-
read.csv("processed data/long AMP data.csv") %>%
dplyr::filter(exclude == FALSE) %>%
dplyr::mutate(participant = as.factor(participant),
rating_factor = as.factor(ifelse(accuracy == 0, "negative",
ifelse(accuracy == 1, "positive", NA)))) %>%
dplyr::rename(prime_type = trialcode,
rating = accuracy)
AMP_summary_data <-
AMP_data %>%
group_by(IAT_condition, prime_type) %>%
dplyr::summarize(mean_rating = round(mean(rating), 2),
sd_rating = round(sd(rating), 2),
se_rating = round(std.error(rating), 2))
AMP_summary_data
# apa theme for all plots
apatheme <-
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
panel.border = element_blank(),
#text = element_text(family='Arial'),  # doesn't play nice with knittr
legend.title = element_blank(),
legend.position = c(.9,.9),
axis.line.x = element_line(color='black'),
axis.line.y = element_line(color='black'))
# add a combined condition*IAT block variable for plotting
AMP_data <-
AMP_data %>%
mutate(exp_factor = paste(IAT_condition, prime_type, sep = "_"))
ggplot(AMP_data,
aes(rating, colour = exp_factor, fill = exp_factor)) +
geom_density(alpha=0.50) +
apatheme
ggplot(AMP_data,
aes(rt, colour = exp_factor, fill = exp_factor)) +
geom_density(alpha=0.50) +
apatheme
AMP_data <-
AMP_data %>%
dplyr::mutate(rt_trimmed = rt) %>%
schoRsch::outlier(dv = "rt_trimmed",
todo = "na",
upper.z = 2.5,
lower.z = -2.5)
ggplot(AMP_data,
aes(rt_trimmed, colour = exp_factor, fill = exp_factor)) +
geom_density(alpha=0.50) +
apatheme
ggplot(data = AMP_summary_data,
aes(x = IAT_condition, y = mean_rating, fill = prime_type)) +
geom_point(data = AMP_data,
aes(x = IAT_condition, y = rating, fill = prime_type),
size = 1,
shape = 16,
alpha = 0.1,
position = position_jitterdodge(dodge.width = .5)) +
geom_violin(data = AMP_data,
aes(x = IAT_condition, y = rating, fill = prime_type),
alpha = 0.5,
position = position_dodge(width = .5)) +
geom_crossbar(aes(ymax = mean_rating + (1.96*se_rating),
ymin = mean_rating + (-1.96*se_rating)),
alpha = 0.5,
fatten = 0) +
geom_point(size = 4,
shape = 15,
position = position_dodge(width = .5)) +
apatheme +
ylab("Rating") +
#coord_cartesian(ylim = c(250,1250))
coord_flip()
ggplot(data = AMP_summary_data,
aes(x = IAT_condition, y = mean_rating, fill = prime_type)) +
# geom_point(data = AMP_data,
#            aes(x = IAT_condition, y = rating, fill = prime_type),
#            size = 1,
#            shape = 16,
#            alpha = 0.1,
#            position = position_jitterdodge(dodge.width = .5)) +
geom_violin(data = AMP_data,
aes(x = IAT_condition, y = rating, fill = prime_type),
alpha = 0.5,
position = position_dodge(width = .5)) +
geom_crossbar(aes(ymax = mean_rating + (1.96*se_rating),
ymin = mean_rating + (-1.96*se_rating)),
alpha = 0.5,
fatten = 0) +
geom_point(size = 4,
shape = 15,
position = position_dodge(width = .5)) +
apatheme +
ylab("Rating") +
#coord_cartesian(ylim = c(250,1250))
coord_flip()
# Check that variables that should be factors are indeed factors
sapply(AMP_data, class)
# LME analysis
model_1 <- afex::mixed(rating ~ prime_type * IAT_condition + modern_racism_scale_total + (1 | participant),
data = AMP_data,
family = binomial,
method = "LR")
print(model_1)
# get data
setwd(params$location_of_data)
ratings_data <-
read.csv("processed data/long ratings data.csv") %>%
dplyr::filter(exclude == FALSE) %>%
dplyr::mutate(participant = as.factor(participant),
IAT_condition = as.factor(IAT_condition))
ratings_summary_data <-
ratings_data %>%
group_by(IAT_condition) %>%
dplyr::summarize(mean_rating = round(mean(rating), 2),
sd_rating = round(sd(rating), 2),
se_rating = round(std.error(rating), 2))
ratings_summary_data
View(ratings_data)
View(ratings_data)
ggplot(ratings_data,
aes(rating, colour = IAT_condition, fill = IAT_condition)) +
geom_density(alpha=0.50) +
apatheme
ggplot(data = ratings_summary_data,
aes(x = IAT_condition, y = mean_rating, fill = IAT_condition)) +
geom_violin(data = ratings_data,
aes(x = IAT_condition, y = rating, fill = IAT_condition),
alpha = 0.5,
position = position_dodge(width = .5)) +
geom_crossbar(aes(ymax = mean_rating + (1.96*se_rating),
ymin = mean_rating + (-1.96*se_rating)),
alpha = 0.5,
fatten = 0) +
geom_point(size = 4,
shape = 15,
position = position_dodge(width = .5)) +
apatheme +
ylab("Rating") +
#coord_cartesian(ylim = c(250,1250))
coord_flip()
# Check that variables that should be factors are indeed factors
sapply(ratings_data, class)
# LME analysis
model_2 <- afex::mixed(rating ~ IAT_condition + modern_racism_scale_total + (1 | participant),
data = ratings_data,
method = "LR")
print(model_2)
# trim exp 2 data
ratings_data_exp2 <-
ratings_data %>%
dplyr::mutate(experiment = 2,
unique_id = as.factor(paste(experiment, participant, sep = "_"))) %>%
dplyr::select(unique_id, experiment, IAT_condition, exclude, rating, modern_racism_scale_total)
# get data from exp 1
setwd(params$location_of_exp_1_data)
ratings_data_exp1 <-
read.csv("processed data/long ratings data.csv") %>%
#dplyr::filter(exclude == FALSE) %>%
dplyr::mutate(experiment = 1,
unique_id = as.factor(paste(experiment, participant, sep = "_")),
IAT_condition = as.factor(IAT_condition),
exclude = ifelse(IAT_exclude_based_on_fast_trials == TRUE, TRUE,
ifelse(SCIAT_exclude_based_on_fast_trials == TRUE, TRUE,
FALSE))) %>%
dplyr::select(unique_id, experiment, IAT_condition, exclude, rating, modern_racism_scale_total)
combined_ratings_data <- rbind(ratings_data_exp1, ratings_data_exp2)
combined_ratings_summary_data <-
combined_ratings_data %>%
group_by(IAT_condition) %>%
dplyr::summarize(mean_rating = round(mean(rating), 2),
sd_rating = round(sd(rating), 2),
se_rating = round(std.error(rating), 2))
ggplot(combined_ratings_data,
aes(rating, colour = IAT_condition, fill = IAT_condition)) +
geom_density(alpha=0.50) +
apatheme
ggplot(data = combined_ratings_summary_data,
aes(x = IAT_condition, y = mean_rating, fill = IAT_condition)) +
geom_violin(data = combined_ratings_data,
aes(x = IAT_condition, y = rating, fill = IAT_condition),
alpha = 0.5,
position = position_dodge(width = .5)) +
geom_crossbar(aes(ymax = mean_rating + (1.96*se_rating),
ymin = mean_rating + (-1.96*se_rating)),
alpha = 0.5,
fatten = 0) +
geom_point(size = 4,
shape = 15,
position = position_dodge(width = .5)) +
apatheme +
ylab("Rating") +
#coord_cartesian(ylim = c(250,1250))
coord_flip()
# Check that variables that should be factors are indeed factors
sapply(ratings_data, class)
# LME analysis
model_3 <- afex::mixed(rating ~ IAT_condition + modern_racism_scale_total + (1 | unique_id),
data = combined_ratings_data,
method = "LR")
print(model_3)
# Screen data
# author: Ian Hussey (ian.hussey@ugent.be)
# license: GPLv3+
# Dependencies ------------------------------------------------------------
library(plyr)
library(tidyverse)
library(data.table)
# Data acquisition and cleaning -------------------------------------------
## Set the working directory
setwd("/Users/Ian/Dropbox/Work/Projects/Analogy/1 analogical learning via IAT with known stimuli/Experiment 2/data/raw data/")
# Read all files with the .iqdat extension
files <- list.files(pattern = "demographics")
# Read these files sequentially into a single data frame
input_df <- dplyr::tbl_df(plyr::rbind.fill(lapply(files, data.table::fread, header = TRUE)))  # tbl_df() requires dplyr, rbind.fill() requires plyr, fread requires data.table
# remove prolific rows and save -------------------------------------------
# NB original file must be deleted too.
prolific_ids_trimmed <- #start with demographics
input_df %>%
dplyr::filter(trialcode != "ProlificCode") %>%
write.csv("demographics.csv")
